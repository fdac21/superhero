{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel XGBClassifier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('superheroes_nlp_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.loc[:, ['name', 'real_name', 'full_name', 'history_text', 'powers_text', 'creator']]\n",
    "# drop all NA's; reduces df by about 46%; 667 rows\n",
    "data.dropna(inplace=True)\n",
    "# remove numbers from the text\n",
    "data['hist'] = df['history_text'].str.lower().replace(r'\\d+', '', regex=True)\n",
    "\n",
    "# get features and labels\n",
    "X = data['hist'].to_numpy()\n",
    "y = data['creator'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/astjohn/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "# create our tfidf vectorizer stuff\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    stop_words=stopwords,\n",
    "    preprocessor=WordNetLemmatizer().lemmatize,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "history_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# one hot encode our labels and features for prediction sake\n",
    "le = LabelEncoder()\n",
    "oe = OneHotEncoder(sparse=False)\n",
    "\n",
    "# integer_X = le.fit_transform(vectorizer.get_feature_names())\n",
    "# integer_X = integer_X.reshape(len(integer_X), 1)\n",
    "# onehot_X = oe.fit_transform(integer_X)\n",
    "\n",
    "integer_y = le.fit_transform(y)\n",
    "integer_y = integer_y.reshape(len(integer_y), 1)\n",
    "onehot_y = oe.fit_transform(integer_y)\n",
    "\n",
    "\n",
    "# get back the original labels\n",
    "# inverted = le.inverse_transform([np.argmax(onehot_y[0])])\n",
    "# this is how we'd get out the actual label names of the encoder\n",
    "# for i in onehot_y:\n",
    "#     print(le.inverse_transform([np.argmax(i)]))\n",
    "\n",
    "# create test and train set\n",
    "X_train, X_test = train_test_split(\n",
    "    history_tfidf,\n",
    "    test_size=0.20,\n",
    "    random_state=42069\n",
    ")\n",
    "y_train, y_test = train_test_split(\n",
    "    onehot_y,\n",
    "    test_size=0.20,\n",
    "    random_state=42069\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the xgbclassifier object\n",
    "multilabel_xgbc = MultiOutputClassifier(\n",
    "    XGBClassifier(n_estimators=200, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# fit the model to our training data\n",
    "multilabel_xgbc_fitted = multilabel_xgbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 73.9%\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test data\n",
    "print(\n",
    "    'Accuracy on test data: {:.1f}%'.format(\n",
    "        accuracy_score(y_test, multilabel_xgbc_fitted.predict(X_test))*100\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
