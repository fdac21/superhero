{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "awful-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grace\n",
    "import sys\n",
    "sys.path.append('src/')\n",
    "import preprocessing as pp\n",
    "from importlib import reload # reload \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#reload(pp)\n",
    "df = pd.read_csv(\"superheroes_nlp_dataset.csv\")\n",
    "\n",
    "### NLP PRE-PROCESSING\n",
    "# replace nulls\n",
    "df = pp.fill_na_columns(df)\n",
    "\n",
    "# lowercase\n",
    "df = pp.lowercase_columns(df)\n",
    "\n",
    "# remove stopwords\n",
    "df = pp.remove_stopwords(df, ['history_text', 'powers_text'])\n",
    "\n",
    "# lematize\n",
    "df = pp.lemmatize_columns(df, ['history_text', 'powers_text'])\n",
    "pd.set_option('display.max_colwidth', None) #Allows you to see the whole row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "atomic-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Empty Lists\n",
    "#df[df.history_text.apply(lambda c: c != [])]\n",
    "#History\n",
    "df = df[df.history_text.apply(lambda c: c != [])] #90\n",
    "#Powers \n",
    "#df = data[data.powers_text.apply(lambda c: c != [])] #Too much missing 375 \n",
    "\n",
    "#Limit Data to Creators who have count > 10\n",
    "#8 Different Comic Creators\n",
    "creators_list = ['marvel comics', 'dc comics', 'shueisha','lego', 'george lucas','image comics','nbc - heroes','dark horse comics' ]\n",
    "df = df[df.creator.isin(creators_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "finnish-fence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marvel comics        583\n",
       "dc comics            414\n",
       "shueisha              35\n",
       "dark horse comics     26\n",
       "lego                  22\n",
       "george lucas          18\n",
       "image comics          16\n",
       "nbc - heroes          15\n",
       "Name: creator, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.creator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "racial-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using just history_text\n",
    "X = df['history_text'].astype('string')\n",
    "y = df['creator']#.to_numpy()\n",
    "\n",
    "# create our tfidf vectorizer stuff\n",
    "vectorizer = TfidfVectorizer(min_df = 10, ngram_range=(1, 2), max_features=10000 ,stop_words = {'one', 'later', 'would', 'also'})\n",
    "history_tfidf = vectorizer.fit_transform(X)\n",
    "history_tfidf =  history_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "actual-superior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>1.749577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>1.757096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>however</th>\n",
       "      <td>1.841709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>1.845824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>him</th>\n",
       "      <td>1.858272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>became</th>\n",
       "      <td>1.925180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventually</th>\n",
       "      <td>1.943198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>1.954627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.977884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>member</th>\n",
       "      <td>2.031036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfidf\n",
       "time        1.749577\n",
       "new         1.757096\n",
       "however     1.841709\n",
       "power       1.845824\n",
       "him         1.858272\n",
       "became      1.925180\n",
       "eventually  1.943198\n",
       "life        1.954627\n",
       "man         1.977884\n",
       "member      2.031036"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  create a dictionary mapping the tokens to their tfidf values\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "tfidf = pd.DataFrame(columns=['tfidf']).from_dict(\n",
    "                    dict(tfidf), orient='index')\n",
    "tfidf.columns = ['tfidf']\n",
    "tfidf.sort_values(by=['tfidf'], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "elder-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = df['creator']#.to_numpy()\n",
    "#X = df.loc[:, ['history_text', 'powers_text']]\n",
    "# one hot encode our labels and features for prediction sake\n",
    "le = LabelEncoder()\n",
    "oe = OneHotEncoder(sparse=False)\n",
    "\n",
    "# integer_X = le.fit_transform(vectorizer.get_feature_names())\n",
    "# integer_X = integer_X.reshape(len(integer_X), 1)\n",
    "# onehot_X = oe.fit_transform(integer_X)\n",
    "\n",
    "integer_y = le.fit_transform(y)\n",
    "integer_y = integer_y.reshape(len(integer_y), 1)\n",
    "onehot_y = oe.fit_transform(integer_y)\n",
    "\n",
    "\n",
    "# get back the original labels\n",
    "# inverted = le.inverse_transform([np.argmax(onehot_y[0])])\n",
    "# this is how we'd get out the actual label names of the encoder\n",
    "# for i in onehot_y:\n",
    "#     print(le.inverse_transform([np.argmax(i)]))\n",
    "\n",
    "# create test and train set\n",
    "X_train, X_test = train_test_split(\n",
    "    history_tfidf,\n",
    "    test_size=0.20,\n",
    "    random_state=42069\n",
    ")\n",
    "y_train, y_test = train_test_split(\n",
    "    onehot_y,\n",
    "    test_size=0.20,\n",
    "    random_state=42069\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "worth-tulsa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903, 5831)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "decimal-blake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 5831)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "flush-allah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marvel comics        583\n",
       "dc comics            414\n",
       "shueisha              35\n",
       "dark horse comics     26\n",
       "lego                  22\n",
       "george lucas          18\n",
       "image comics          16\n",
       "nbc - heroes          15\n",
       "Name: creator, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.creator.value_counts() #1129 - Naive for marvel 0.516386182462356"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "speaking-egypt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.516386182462356"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuning Parameters \n",
    "# n_estimators : the number of trees in the forest of the model\n",
    "# max_depth: maximum depth of each tree, dont touch\n",
    "# min_samples_split: minimum number of samples required to split an internal leaf node.\n",
    "# min_samples_leaf: minimum number of samples required to be at a leaf node.\n",
    "#criterion{“gini”, “entropy”}, default=”gini”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "solid-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [200, 300, 400], #[100, 150, 200,.1000] #200 consistently the best\n",
    "    'max_features': ['sqrt'],\n",
    "    'criterion': ['gini']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "honest-activity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=545),\n",
       "             param_grid={'criterion': ['gini'], 'max_features': ['sqrt'],\n",
       "                         'n_estimators': [200, 300, 400]})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc=RandomForestClassifier(random_state=545)\n",
    "\n",
    "RF_grid = GridSearchCV(rfc, param_grid=param_grid)\n",
    "RF_grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "italian-diagram",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 200}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "willing-fundamentals",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ACCURACY OF THE MODEL:  0.7610619469026548\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 200 ,random_state=545)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn import metrics \n",
    "print()\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))\n",
    "#Need to beat 74% Accuracy (100 trees) in Tuning \n",
    "# ACCURACY OF THE MODEL:  0.7433628318584071 with 10000\n",
    "# ACCURACY OF THE MODEL:  0.7477876106194691\n",
    "# ACCURACY OF THE MODEL:  0.7610619469026548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "adaptive-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dark horse comics': 0, 'dc comics': 1, 'george lucas': 2, 'image comics': 3, 'lego': 4, 'marvel comics': 5, 'nbc - heroes': 6, 'shueisha': 7}\n"
     ]
    }
   ],
   "source": [
    "name_mappings = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(name_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "opposite-grenada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3,   0,   0,   0,   0,   3,   0,   0],\n",
       "       [ 14,  64,   0,   0,   0,   9,   0,   0],\n",
       "       [  3,   0,   0,   0,   0,   2,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   2,   0,   0],\n",
       "       [  1,   1,   0,   0,   1,   0,   0,   0],\n",
       "       [  4,   4,   0,   0,   1, 105,   0,   0],\n",
       "       [  3,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  2,   0,   0,   0,   0,   1,   0,   2]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
